{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building a Neural Network from Scratch**\n",
    "The goal of this tutorial is to outline the necessary steps to build an Artificial Neural Network (ANN) from the ground up, explaining in theory the various elements required for its construction, training, and practical application. To achieve this, we will implement a Feedforward Neural Network, where information flows from the network's input layers, stimulating the network's neurons, and producing an output.\n",
    "\n",
    "The following topics will be covered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Table of Contents**\n",
    "- [1 - Environment Preparation](#1)\n",
    "- [2 - Layer Initialization](#2)\n",
    "- [3 - Parameter Initialization](#3)\n",
    "- [4 - Implementing Forward Propagation](#4)\n",
    "- [5 - Cost Computation](#5)\n",
    "- [6 - Implementing Backward Propagation](#6)\n",
    "- [7 - Parameter Update (Gradient Descent)](#7)\n",
    "- [8 - Model Training](#8)\n",
    "- [9 - Prediction](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "# **1.- Environment Setup**\n",
    "First, all the necessary libraries for the implementation are installed and imported.\n",
    "\n",
    "## 1.1.- Library Installation\n",
    "Primarily, `numpy` and `matplotlib` will be used for some visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install --upgrade jupyter\n",
    "%pip install --upgrade notebook\n",
    "%pip install jupyterlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding with the construction of the neural network, it is important to check that the GPU is available for use. To do this, the following function from the `Tensorflow` library can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 16:04:44.063003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 16:04:44.175236: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 16:04:44.207161: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 16:04:44.414708: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724947487.557571     630 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724947487.639426     630 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724947487.639471     630 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a graphics card is reported as available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.- Libraries Initalization\n",
    "Once installed, the libraries are initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.chdir('/app/functions')\n",
    "\n",
    "# I will also import activation functions, which are crucial for correct working of the net\n",
    "from activation_functions import relu, sigmoid, sigmoid_backward, relu_backward\n",
    "\n",
    "os.chdir('/app/notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.- Loading the Dataset\n",
    "For training the neural network, we will use the CIFAR-10 dataset. This dataset consists of 60,000 color images, each of size 32x32, categorized into 10 classes (with 6,000 images per class). The data is divided into 50,000 training images and 10,000 test images. The classes are: 'Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By extracting the images from the TensorFlow library, we will distinguish between the training dataset (x_train) and its corresponding labels (y_train), and the test data. However, to input the images into our neural network, all images need to be flattened (into a single vector) and standardized.\n",
    "\n",
    "Moreover, since the objective is to solve a binary classification task, we will filter for only 2 classes. We will focus on distinguishing between 'Truck' and 'Frog'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN - The dimensions of the images are now  (3072, 10000)\n",
      "TEST - The dimensions of the images are now  (3072, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Filtering training and test data\n",
    "train_indices = np.where((y_train == 9) | (y_train == 6))[0]\n",
    "x_train = x_train[train_indices]\n",
    "y_train = y_train[train_indices]\n",
    "y_train = np.where(y_train == 9, 0, 1)\n",
    "\n",
    "test_indices = np.where((y_test == 9) | (y_test == 6))[0]\n",
    "x_test = x_test[test_indices]\n",
    "y_test = y_test[test_indices]\n",
    "y_test = np.where(y_test == 9, 0, 1)\n",
    "\n",
    "# Flattening the training and test images\n",
    "x_train_flattened = x_train.reshape(x_train.shape[0], -1).T\n",
    "x_test_flattened = x_test.reshape(x_test.shape[0], -1).T\n",
    "\n",
    "# Standardizing the pixels\n",
    "x_train_flattened_standardized = x_train_flattened / 255.0\n",
    "x_test_flattened_standardized = x_test_flattened / 255.0\n",
    "\n",
    "# Displaying the new dimensions of the images\n",
    "print(\"TRAIN - The dimensions of the images are now \", str(x_train_flattened_standardized.shape))\n",
    "print(\"TEST - The dimensions of the images are now \", str(x_test_flattened_standardized.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the size of the dataset, I visualize an initial example of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(dataset, index_image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    \n",
    "    # Remove axis labels\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(dataset[index_image])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_image(x_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "# **2.- Initialization of Layers**\n",
    "First, some parameters of the network must be decided, which will allow us to create its architecture. These parameters include the number of hidden layers and the number of neurons in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layers(X, Y, num_hidden_layers, num_hidden_units):\n",
    "    \"\"\"_summary_\n",
    "    This method defines the structure of the neural network by specifying the number of neurons in the input layer (which is determined by the size of the dataset used),\n",
    "    the number of hidden layers specified by an input parameter, the number of neurons in each of these hidden layers, and finally, the number of neurons in the output layer \n",
    "    (determined by the size of the target variable).\n",
    "\n",
    "    It is understood that this is building a Deep Neural Network where all hidden layers have the same number of neurons.\n",
    "\n",
    "    Args:\n",
    "        X (class 'numpy.ndarray'): input dataset (input size, number of examples)\n",
    "        Y (class 'numpy.ndarray'): labels (output size, number of examples)\n",
    "        num_hidden_layers (class 'int'): number of hidden layers of the network\n",
    "        num_hidden_units (class 'list'): list containing number of nodes per layer.    \n",
    "    \n",
    "    Returns:\n",
    "        dim_layers (class 'list'): list containing number of nodes per layer, incluiding input and output layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an array to store the network layer structure\n",
    "    dim_layers = []\n",
    "\n",
    "    # Define the number of neurons in the input layer\n",
    "    input_units = X.shape[1]*X.shape[2]*X.shape[3]\n",
    "\n",
    "    # Add the first layer, in this case, the input layer\n",
    "    dim_layers.append(input_units)\n",
    "\n",
    "    # Iterate over the number of hidden layers\n",
    "    for i in range(0,num_hidden_layers):\n",
    "        dim_layers.append(num_hidden_units[i])\n",
    "\n",
    "    # Finally, add the output layer\n",
    "    output_units = Y.shape[1]\n",
    "    dim_layers.append(output_units)\n",
    "\n",
    "    return dim_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the method to initialize the network structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = init_layers(X = x_train, Y = y_train, num_hidden_layers = 3, num_hidden_units = [2000, 800, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "# **3.- Parameter Initialization**\n",
    "This method allows us to initialize the parameters for a neural network with `l` layers. Both weights and biases will be initialized using this method. Dimensions will be as follows:\n",
    "$$Weights, W = (n^{[l]}, n^{[l-1]})$$\n",
    "$$Bias, b = (n^{[l]}, 1)$$\n",
    "This means, Weights matrix will have one row for every node in the layer initialized and one column for every node of the previous layer. What about the first layer? Well, we'll have:\n",
    "* ${n^{[l]} = }$ num. of nodes in the actual layer.\n",
    "* ${n^{[l-1]} = }$ num. of pixels in input images.\n",
    "\n",
    "Also, what about the values? Well:\n",
    "\n",
    "* $Weights, W$: it is important to initialize all weights to small random values. The technique used in this example is the `He Initialization`, that takes into account the non-linearity of activation functions, reducing the magnitudes of input signals exponentially. In this initialization method, we'll multiply small random values with $\\sqrt{\\frac{2}{\\text{dimension of the previous layer}}}$, which is what He initialization recommends for layers with a ReLU activation.\n",
    "\n",
    "* $Bias, b$: these can be initialized with small random positive values or zeros. In this example, we've used zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def init_parameters(dims_layers):\n",
    "    \"\"\"_summary_\n",
    "    This function initializes the parameters of the Neural Network based on the structure defined in the previous function.\n",
    "\n",
    "    Args:\n",
    "        dims_layers (class 'list'): list containing number of nodes per layer, incluiding input and output layers.\n",
    "\n",
    "    Returns:\n",
    "        parameters (class 'dict'): dictionary consisting of the set of initialized parameters in the network.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary to store the parameters\n",
    "    parameters = {}\n",
    "\n",
    "    for num_capa in range(1, len(dims_layers)):\n",
    "        # For each layer, create the corresponding weight matrix and bias.\n",
    "        parameters['W' + str(num_capa)] = np.random.randn(dims_layers[num_capa], dims_layers[num_capa-1]) * (np.sqrt(2/dims_layers[num_capa-1]))\n",
    "        parameters['b' + str(num_capa)] = np.zeros((dims_layers[num_capa], 1))\n",
    "\n",
    "    # Return the initialized parameters\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "# **4.- Implementation of 'Forward Propagation'**\n",
    "To implement forward propagation, the following calculations need to be performed:\n",
    "* Calculation of the pre-activation parameters.\n",
    "* Calculation of the activation of the neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.- Pre-Activation Parameters\n",
    "This method calculates the parameters that are input into the neuron's activation function. The equation used is:\n",
    "\n",
    "$$Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}\\$$\n",
    "\n",
    "where ${[l]}$ denotes the layer number; $W^{[l]}$ represents the current weights of the current layer; $A^{[l-1]}$ is the activation of the previous layer; and $b^{[l]}$ is the bias of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pre_activation(A, W, b):\n",
    "    \"\"\"_summary_\n",
    "    This function calculates the pre-activation parameters of a layer.\n",
    "    \n",
    "    Args:\n",
    "        A (class 'numpy.ndarray'): consists of the activations obtained from the previous layer.\n",
    "        W (class 'numpy.ndarray'): consists of the current weights of the layer.\n",
    "        b (class 'numpy.ndarray'): consists of the current bias of the layer.\n",
    "\n",
    "    Returns:\n",
    "        Z (class 'numpy.ndarray'): consists of the pre-activation params. obtained.\n",
    "        pre_activation_params (class 'tuple'): tuple containing A, W, b, stored to speed up network training.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the pre-activation parameters\n",
    "    Z = np.dot(W,A) + b\n",
    "\n",
    "    # Create a Python tuple stored in cache to speed up network training, as these parameters will be used later\n",
    "    pre_activation_params = (A, W, b)\n",
    "\n",
    "    return Z, pre_activation_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.- Calculation of Layer Activation\n",
    "Based on the pre-activation parameters calculated earlier, the appropriate activation function must be applied to the resulting matrix. In this case, all hidden layers will use the ReLU activation function, while the output layer will employ the sigmoid function.\n",
    "$$A^{[l]} = g(Z^{[l]}) = g(W^{[l]}A^{[l-1]} +b^{[l]})$$\n",
    "where `g()` can be a Sigmoid or ReLU function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_activation(dataset, parameters):\n",
    "    \"\"\"_summary_\n",
    "    Function that computes the activation of a layer.\n",
    "\n",
    "    Args:\n",
    "        dataset (class 'numpy.ndarray'): Input data. Used to determine the number of neurons in the input layer.\n",
    "        parameters (class 'dict'): Python dictionary with the initialized parameters based on the network structure: weights and biases.\n",
    "\n",
    "    Returns:\n",
    "        AL (class 'numpy.ndarray'): Activation of the final layer.\n",
    "        cache (class 'list'): Tuple containing the activation of the previous layer (A_prev), weights of the current layer (W), and bias (b).\n",
    "    \"\"\"\n",
    "\n",
    "    # Store the results in cache to speed up network training\n",
    "    caches = []\n",
    "\n",
    "    # Number of hidden layers\n",
    "    hidden_layers = len(parameters) // 2\n",
    "\n",
    "    # For the first layer, activation functions are the input data\n",
    "    A = dataset\n",
    "\n",
    "    # Compute activation for hidden layers\n",
    "    for num_layer in range(1, hidden_layers):\n",
    "        Z, pre_activation_params = pre_activation(A, parameters['W' + str(num_layer)], parameters['b' + str(num_layer)])\n",
    "        A, cache = relu(Z)\n",
    "        cache = (pre_activation_params, cache)\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Compute activation for the final layer\n",
    "    Z, pre_activation_params = pre_activation(A, parameters['W' + str(hidden_layers)], parameters['b' + str(hidden_layers)])\n",
    "    AL, cache = sigmoid(Z)\n",
    "    cache = (pre_activation_params, cache)\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "# **5.- Computation of Loss**\n",
    "At this point, the activation of each layer has already been computed, so we just need to compute the cost. The cost defines the error between the model's predictions and the actual labels of the dataset. To ensure that our model is learning correctly, the cost should decrease at each stage of training.\n",
    "\n",
    "Since we are working with a binary classification problem, we will use binary cross-entropy as the loss function. However, it is important to note that different loss functions can be used depending on the problem being addressed or the metric that is prioritized for optimization.\n",
    "\n",
    "<!--  -->\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right)) \\$$\n",
    "\n",
    "\n",
    "Below is the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(predictions, Y):\n",
    "    \"\"\"_summary_\n",
    "    Function that calculates the error between the model's predictions and the correct labels.\n",
    "\n",
    "    Args:\n",
    "        predictions (class 'numpy.ndarray'): network predictions.\n",
    "        Y (class 'numpy.ndarray'): true labels.\n",
    "\n",
    "    Returns:\n",
    "        cost (class 'numpy.float64'): error obtained from network predictions compared to true labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the loss function\n",
    "    cost = - np.mean( Y * np.log(predictions) + (1-Y) * np.log(1-predictions)) \n",
    "\n",
    "    cost = np.squeeze(cost) \n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "# **6.- Implementation of Backward Propagation**\n",
    "\n",
    "The backpropagation algorithm enables the information about the cost obtained during forward propagation to be propagated backward (in the opposite direction of forward propagation) with the goal of computing the gradient. It is important to distinguish this process from parameter updates, which are carried out by another algorithm, such as stochastic gradient descent.\n",
    "\n",
    "## 6.1.- Linear backward activation\n",
    "To implement backward propagation, multiple calculations will be necessary. First, the linear activation, starting from the activation of the last layer:\n",
    "\n",
    "Having the derivative `dZ`:\n",
    "\n",
    "$$dW^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T} \\$$\n",
    "\n",
    "\n",
    "$$db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)} \\$$\n",
    "\n",
    "\n",
    "$$dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} \\$$\n",
    "\n",
    "where `m` is the number of examples of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"_summary_\n",
    "    Function to compute the backward propagation for a single layer.\n",
    "    \n",
    "    Args:\n",
    "        dZ (class 'numpy.ndarray'): Gradient of the cost with respect to the output.\n",
    "        cache (class 'tuple'): Activation values from the previous layer (A_prev), weights (W), and bias (b) of the current layer.\n",
    "    \n",
    "    Returns:\n",
    "        dA_prev (class 'numpy.ndarray'): derivatives obtained from activations of prev. layer\n",
    "        dW (class 'numpy.ndarray'): derivatives obtained from weights of actual layer.\n",
    "        db (class 'numpy.ndarray'): derivatives obtained from bias of actual layer.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve values from the cache\n",
    "    A_prev, W, b = cache\n",
    "\n",
    "    # Get the number of examples\n",
    "    num_examples = A_prev.shape[1]\n",
    "\n",
    "    # Calculate gradients with respect to W, b, and the activation layer\n",
    "    dW = (1/num_examples) * np.dot(dZ, np.transpose(A_prev))\n",
    "    db = (1/num_examples) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(np.transpose(W), dZ)\n",
    "\n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.- Implementation of Backward Propagation\n",
    "Finally, the complete backward propagation method is implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(dZ, Y, cache):\n",
    "    \"\"\"_summary_\n",
    "    Function that implements 'backward propagation' for a single layer.\n",
    "\n",
    "    Args:\n",
    "        dZ (class 'numpy.ndarray'): Gradient of the cost with respect to the output.\n",
    "        Y (class 'numpy.ndarray'): true labels.\n",
    "        cache (class 'list'): Tuple containing the activation of the previous layer (A_prev), weights of the current layer (W), and bias (b).\n",
    "\n",
    "    Return:\n",
    "        gradients (class 'dict'): Python dictionary containing the gradients for each layer.\n",
    "    \"\"\"\n",
    "    # Initialize the gradient vector\n",
    "    gradients = {}\n",
    "\n",
    "    # The number of layers can be determined directly from the number of caches\n",
    "    num_layers = len(cache)\n",
    "\n",
    "    Y = Y.reshape(dZ.shape)\n",
    "    \n",
    "    # To avoid logarithms and divisions by 0\n",
    "    epsilon = 1e-15\n",
    "    AL = np.clip(dZ, epsilon, 1 - epsilon)\n",
    "\n",
    "    # Initialize backward propagation by calculating the derivative of the final activation layer\n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    # Start with the final layer, from which parameters can be obtained using the 'linear_activation_backward' function\n",
    "    cache_actual = cache[num_layers-1]\n",
    "    linear_cache, activation_cache = cache_actual\n",
    "    dZ = sigmoid_backward(dAL, activation_cache)\n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    gradients['dA'+str(num_layers-1)] = dA_prev\n",
    "    gradients['dW'+str(num_layers)] = dW\n",
    "    gradients['db'+str(num_layers)] = db\n",
    "\n",
    "    # Iterate from the last layer to the first, i.e., in reverse order\n",
    "    for num_layer in reversed(range(num_layers-1)):\n",
    "        # Retrieve the cache for the layer\n",
    "        cache_actual = cache[num_layer]\n",
    "        linear_cache, activation_cache = cache_actual\n",
    "\n",
    "        # Calculate the backward linear activation\n",
    "        dZ = relu_backward(gradients['dA'+str(num_layer+1)], activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        gradients['dA'+str(num_layer)] = dA_prev\n",
    "        gradients['dW'+str(num_layer+1)] = dW\n",
    "        gradients['db'+str(num_layer+1)] = db\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "# **7.- Parameter Update (Gradient Descent)**\n",
    "Once the backward propagation has been computed for the weights and biases of each layer in the network, the parameters need to be updated using the learning rate. This rate determines how aggressively each parameter will be adjusted.\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} \\$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} \\$$\n",
    "where $\\alpha$ is the parameter learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def update_parameters(parameters, gradients, lrate):\n",
    "    \"\"\"_summary_\n",
    "    Function that updates parameters using gradient descent.\n",
    "\n",
    "    Args:\n",
    "        parameters (class 'dict'): dictionary consisting of the set of initialized parameters in the network.\n",
    "        gradients (class 'dict'): Python dictionary containing the gradients for each layer.\n",
    "        lrate (class 'numpy.float64'): learning rate value.\n",
    "\n",
    "    Returns:\n",
    "        params (class 'dict'): dictionary consisting of the set of updated parameters in the network.\n",
    "    \"\"\"\n",
    "    params = copy.deepcopy(parameters)\n",
    "    \n",
    "    # Number of hidden layers\n",
    "    hidden_layers = len(params) // 2\n",
    "    \n",
    "    # Update the parameters across the entire network\n",
    "    for num_layer in range(hidden_layers):\n",
    "        params[\"W\" + str(num_layer+1)] = params[\"W\" + str(num_layer+1)] - lrate * gradients['dW' + str(num_layer+1)]\n",
    "        params[\"b\" + str(num_layer+1)] = params[\"b\" + str(num_layer+1)] - lrate * gradients['db' + str(num_layer+1)]\n",
    "        \n",
    "    # Return the updated parameters (weights and bias)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "# **8.- Training the Model**\n",
    "Finally, the network training process begins. The process of forwarding information through the entire network, calculating gradients, and updating parameters will be repeated for a specified number of iterations: `num_iterations`. The error for each iteration will be returned for both the training set, from which the network learns, and the validation set, which is not used to compute gradients or update parameters. Thus, the network will be evaluated in each iteration with \"unseen\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, Y, val_x, val_y, model, lrate, num_iterations):\n",
    "    \"\"\"_summary_\n",
    "    Function that optimize the neural network.\n",
    "\n",
    "    Args:\n",
    "        X (class 'numpy.ndarray'): training dataset.\n",
    "        Y (class 'numpy.ndarray'): training labels.\n",
    "        val_x (class 'numpy.ndarray'): validation dataset.\n",
    "        val_y (class 'numpy.ndarray'): validation labels.\n",
    "        model (class 'list'): list containing number of nodes per layer, including input and output layers.\n",
    "        lrate (class 'numpy.float64'): learning rate value.\n",
    "        num_iterations (class 'int'): number of training iterations through dataset.\n",
    "\n",
    "    Returns:\n",
    "        parameters (class 'dict'): dictionary consisting of the set of updated parameters from the network after training.\n",
    "        loss_train (class 'list'): list of training error progression throughout optimization.\n",
    "        loss_val (class 'list'): list of validation error progression throughout optimization.\n",
    "        error (class 'numpy.float64'): error obtained on the last iteration, which means the error of the network with training dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    gradients = {}\n",
    "    \n",
    "    # To store the error after each iteration\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "\n",
    "    # Adjust the shape of the labels\n",
    "    Y = Y.T\n",
    "    val_y = val_y.T\n",
    "\n",
    "    # 1.- Initialize the parameters\n",
    "    parameters = init_parameters(model)\n",
    "\n",
    "    # 2.- Training iteration\n",
    "    for i in range(0, num_iterations):\n",
    "        \n",
    "        # First, call 'forward_activation'\n",
    "        AL, cache = forward_activation(X, parameters)\n",
    "        \n",
    "        # For validation:\n",
    "        AL_val, cache_val = forward_activation(val_x, parameters)\n",
    "\n",
    "        # Adapt the predictions to avoid errors when calculating logarithms\n",
    "        epsilon = 1e-15\n",
    "        AL = np.clip(AL, epsilon, 1 - epsilon)\n",
    "        \n",
    "        # Compute the current error\n",
    "        error = cost_function(AL, Y)\n",
    "        val_error = cost_function(AL_val, val_y)\n",
    "\n",
    "        # Initialize 'backward propagation'\n",
    "        gradients = backward_propagation(AL, Y, cache)\n",
    "        \n",
    "        # Update the parameters to accelerate training\n",
    "        parameters = update_parameters(parameters, gradients, lrate)\n",
    "\n",
    "        # Display the error in the console\n",
    "        print(\"Epoch \", i, \" --- Training Error: \", error, \" --- Val. Error: \", val_error)\n",
    "        \n",
    "        # Save the error of the iteration\n",
    "        loss_train.append(error)\n",
    "        loss_val.append(val_error)\n",
    "    \n",
    "    # Return the network parameters after training\n",
    "    return parameters, loss_train, loss_val, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  --- Training Error:  0.8500716377865228  --- Val. Error:  0.8587394430667517\n",
      "Epoch  1  --- Training Error:  0.9853685646688842  --- Val. Error:  0.9939569493006509\n",
      "Epoch  2  --- Training Error:  0.9232865388896638  --- Val. Error:  0.9370473546154416\n",
      "Epoch  3  --- Training Error:  0.6806662401270008  --- Val. Error:  0.6865924141118418\n",
      "Epoch  4  --- Training Error:  0.5890640132622397  --- Val. Error:  0.5960462589282138\n",
      "Epoch  5  --- Training Error:  0.5556989971423054  --- Val. Error:  0.5619904752815831\n",
      "Epoch  6  --- Training Error:  0.5324737098186558  --- Val. Error:  0.5391811064577016\n",
      "Epoch  7  --- Training Error:  0.514620022549121  --- Val. Error:  0.5213964390687288\n",
      "Epoch  8  --- Training Error:  0.4992835165441495  --- Val. Error:  0.5064654783861438\n",
      "Epoch  9  --- Training Error:  0.4863913853854665  --- Val. Error:  0.49363671612068827\n",
      "Epoch  10  --- Training Error:  0.47512206430597237  --- Val. Error:  0.4826864494766095\n",
      "Epoch  11  --- Training Error:  0.46579241448163783  --- Val. Error:  0.47312194168799265\n",
      "Epoch  12  --- Training Error:  0.45814135661339117  --- Val. Error:  0.4657173212381365\n",
      "Epoch  13  --- Training Error:  0.4527617378065312  --- Val. Error:  0.4600159824865346\n",
      "Epoch  14  --- Training Error:  0.450320251671388  --- Val. Error:  0.45829554615506857\n",
      "Epoch  15  --- Training Error:  0.451409926206636  --- Val. Error:  0.4589227651285489\n",
      "Epoch  16  --- Training Error:  0.45932498951672607  --- Val. Error:  0.46851453110631247\n",
      "Epoch  17  --- Training Error:  0.47059670535039877  --- Val. Error:  0.4789701049485889\n",
      "Epoch  18  --- Training Error:  0.490521297244473  --- Val. Error:  0.501790128441523\n",
      "Epoch  19  --- Training Error:  0.49827183457329327  --- Val. Error:  0.5076089192622062\n",
      "Epoch  20  --- Training Error:  0.5035399444407044  --- Val. Error:  0.5158486712456132\n",
      "Epoch  21  --- Training Error:  0.49056062719757504  --- Val. Error:  0.5000597665349553\n",
      "Epoch  22  --- Training Error:  0.470904552221553  --- Val. Error:  0.48240125705930154\n",
      "Epoch  23  --- Training Error:  0.4573216099035739  --- Val. Error:  0.46625725323510375\n",
      "Epoch  24  --- Training Error:  0.4449997804548172  --- Val. Error:  0.4556212343112602\n",
      "Epoch  25  --- Training Error:  0.43440180951391083  --- Val. Error:  0.44293022225473805\n",
      "Epoch  26  --- Training Error:  0.42624956528585134  --- Val. Error:  0.43629034117157317\n",
      "Epoch  27  --- Training Error:  0.41912152095609373  --- Val. Error:  0.4273879832029975\n",
      "Epoch  28  --- Training Error:  0.41441191727842386  --- Val. Error:  0.4241022733845042\n",
      "Epoch  29  --- Training Error:  0.4093999411729489  --- Val. Error:  0.4175046047851542\n",
      "Epoch  30  --- Training Error:  0.40637778790439716  --- Val. Error:  0.41587891817530453\n",
      "Epoch  31  --- Training Error:  0.4028669701636235  --- Val. Error:  0.410827970525837\n",
      "Epoch  32  --- Training Error:  0.4010283424898209  --- Val. Error:  0.4104488484712075\n",
      "Epoch  33  --- Training Error:  0.39841938533622767  --- Val. Error:  0.4062599288197417\n",
      "Epoch  34  --- Training Error:  0.3972699977140813  --- Val. Error:  0.40668419341821044\n",
      "Epoch  35  --- Training Error:  0.3953510424626955  --- Val. Error:  0.40310454110116783\n",
      "Epoch  36  --- Training Error:  0.3946672244293012  --- Val. Error:  0.40412402169087475\n",
      "Epoch  37  --- Training Error:  0.3931248593166906  --- Val. Error:  0.400792823061163\n",
      "Epoch  38  --- Training Error:  0.3928932701020769  --- Val. Error:  0.40242897544896866\n",
      "Epoch  39  --- Training Error:  0.3915789187388944  --- Val. Error:  0.3991501978181077\n",
      "Epoch  40  --- Training Error:  0.39157398760119405  --- Val. Error:  0.40120762912715474\n",
      "Epoch  41  --- Training Error:  0.3902327139578017  --- Val. Error:  0.39769986010486036\n",
      "Epoch  42  --- Training Error:  0.39023198633074124  --- Val. Error:  0.39995933898586544\n",
      "Epoch  43  --- Training Error:  0.3888846119343266  --- Val. Error:  0.39624234987198714\n",
      "Epoch  44  --- Training Error:  0.38869958161490187  --- Val. Error:  0.39849318337589873\n",
      "Epoch  45  --- Training Error:  0.38719739116263563  --- Val. Error:  0.39442947939275463\n",
      "Epoch  46  --- Training Error:  0.386890026362396  --- Val. Error:  0.3967322835731089\n",
      "Epoch  47  --- Training Error:  0.38523765269781374  --- Val. Error:  0.3923434760104152\n",
      "Epoch  48  --- Training Error:  0.3846358286194931  --- Val. Error:  0.39449146210720204\n",
      "Epoch  49  --- Training Error:  0.38280717236439094  --- Val. Error:  0.3897927837778476\n",
      "Epoch  50  --- Training Error:  0.38204924643205296  --- Val. Error:  0.3918905566188536\n",
      "Epoch  51  --- Training Error:  0.3801383178966813  --- Val. Error:  0.38700745317497587\n",
      "Epoch  52  --- Training Error:  0.37928346275898617  --- Val. Error:  0.38908706383369257\n",
      "Epoch  53  --- Training Error:  0.3773592098097937  --- Val. Error:  0.3841162459701007\n",
      "Epoch  54  --- Training Error:  0.37648783382987355  --- Val. Error:  0.38624414859816547\n",
      "Epoch  55  --- Training Error:  0.37465653648423974  --- Val. Error:  0.38129597299343154\n",
      "Epoch  56  --- Training Error:  0.3738111647720451  --- Val. Error:  0.38352358881413795\n",
      "Epoch  57  --- Training Error:  0.3720293190885179  --- Val. Error:  0.3785564018269108\n",
      "Epoch  58  --- Training Error:  0.3711923006734366  --- Val. Error:  0.3808565650795\n",
      "Epoch  59  --- Training Error:  0.3694796240739422  --- Val. Error:  0.3758933025073579\n",
      "Epoch  60  --- Training Error:  0.3688202016365901  --- Val. Error:  0.3784392370911503\n",
      "Epoch  61  --- Training Error:  0.3672171182339783  --- Val. Error:  0.3735311344019087\n",
      "Epoch  62  --- Training Error:  0.36659739324034624  --- Val. Error:  0.3761777892505332\n",
      "Epoch  63  --- Training Error:  0.3650842636944383  --- Val. Error:  0.3713148162183245\n",
      "Epoch  64  --- Training Error:  0.36459930531824863  --- Val. Error:  0.37416110046574425\n",
      "Epoch  65  --- Training Error:  0.3632374406691284  --- Val. Error:  0.3693867240774004\n",
      "Epoch  66  --- Training Error:  0.3628504486337749  --- Val. Error:  0.3724026607569986\n",
      "Epoch  67  --- Training Error:  0.36154556037752444  --- Val. Error:  0.3676100092516183\n",
      "Epoch  68  --- Training Error:  0.36121957069978233  --- Val. Error:  0.3707624159805097\n",
      "Epoch  69  --- Training Error:  0.3600511665422017  --- Val. Error:  0.36602985915064123\n",
      "Epoch  70  --- Training Error:  0.3598336929027586  --- Val. Error:  0.3693777887351665\n",
      "Epoch  71  --- Training Error:  0.35878825425048155  --- Val. Error:  0.3646842187594466\n",
      "Epoch  72  --- Training Error:  0.3586171067629321  --- Val. Error:  0.3681695407995089\n",
      "Epoch  73  --- Training Error:  0.3576789720839224  --- Val. Error:  0.36349698262092994\n",
      "Epoch  74  --- Training Error:  0.3575786861270139  --- Val. Error:  0.3671522096329232\n",
      "Epoch  75  --- Training Error:  0.3566375418657589  --- Val. Error:  0.3623817301000679\n",
      "Epoch  76  --- Training Error:  0.356607794055233  --- Val. Error:  0.36619479011778805\n",
      "Epoch  77  --- Training Error:  0.35565633555740567  --- Val. Error:  0.3613413073530721\n",
      "Epoch  78  --- Training Error:  0.35557958554914637  --- Val. Error:  0.36517145936194684\n",
      "Epoch  79  --- Training Error:  0.35461207454256766  --- Val. Error:  0.36023662249300775\n",
      "Epoch  80  --- Training Error:  0.35455477233149907  --- Val. Error:  0.3641510533458005\n",
      "Epoch  81  --- Training Error:  0.35361509250096523  --- Val. Error:  0.3591729672129847\n",
      "Epoch  82  --- Training Error:  0.35356601762966006  --- Val. Error:  0.3631622241873696\n",
      "Epoch  83  --- Training Error:  0.3526326751941857  --- Val. Error:  0.3581267323722522\n",
      "Epoch  84  --- Training Error:  0.3525295859469942  --- Val. Error:  0.36212397717908923\n",
      "Epoch  85  --- Training Error:  0.3515646100873304  --- Val. Error:  0.35699381167412036\n",
      "Epoch  86  --- Training Error:  0.35146654778558933  --- Val. Error:  0.3610555066930349\n",
      "Epoch  87  --- Training Error:  0.35049947105284  --- Val. Error:  0.35586230753476267\n",
      "Epoch  88  --- Training Error:  0.350392985807461  --- Val. Error:  0.3599676056477301\n",
      "Epoch  89  --- Training Error:  0.34942106267308326  --- Val. Error:  0.35471838819203244\n",
      "Epoch  90  --- Training Error:  0.3493357307581659  --- Val. Error:  0.35889669964854554\n",
      "Epoch  91  --- Training Error:  0.3482976309088085  --- Val. Error:  0.3535329911374476\n",
      "Epoch  92  --- Training Error:  0.3481593044844026  --- Val. Error:  0.35769116121938455\n",
      "Epoch  93  --- Training Error:  0.34708629635509636  --- Val. Error:  0.3522663115265288\n",
      "Epoch  94  --- Training Error:  0.3469285484888236  --- Val. Error:  0.35641815842293445\n",
      "Epoch  95  --- Training Error:  0.34583324429397116  --- Val. Error:  0.3509617522709565\n",
      "Epoch  96  --- Training Error:  0.34565457021609575  --- Val. Error:  0.3550933027115827\n",
      "Epoch  97  --- Training Error:  0.3445219900264185  --- Val. Error:  0.34960506687212867\n",
      "Epoch  98  --- Training Error:  0.3443129910439384  --- Val. Error:  0.35369294878162066\n",
      "Epoch  99  --- Training Error:  0.3431490278294477  --- Val. Error:  0.3481820769741072\n",
      "Epoch  100  --- Training Error:  0.34291307828840706  --- Val. Error:  0.35222511119035244\n",
      "Epoch  101  --- Training Error:  0.3418096436724324  --- Val. Error:  0.346790506069883\n",
      "Epoch  102  --- Training Error:  0.34156089309003324  --- Val. Error:  0.35080897918326454\n",
      "Epoch  103  --- Training Error:  0.34052141957891724  --- Val. Error:  0.3454472625806279\n",
      "Epoch  104  --- Training Error:  0.34028352788332605  --- Val. Error:  0.3494682299775016\n",
      "Epoch  105  --- Training Error:  0.3392247573136408  --- Val. Error:  0.344095187443167\n",
      "Epoch  106  --- Training Error:  0.3390250698362273  --- Val. Error:  0.34814524125942925\n",
      "Epoch  107  --- Training Error:  0.3379640768469842  --- Val. Error:  0.3427798124032481\n",
      "Epoch  108  --- Training Error:  0.3377550617149896  --- Val. Error:  0.34680855496394736\n",
      "Epoch  109  --- Training Error:  0.3367713445869377  --- Val. Error:  0.341532711079274\n",
      "Epoch  110  --- Training Error:  0.3365797007380058  --- Val. Error:  0.345576514128526\n",
      "Epoch  111  --- Training Error:  0.335678243909611  --- Val. Error:  0.34038308950440305\n",
      "Epoch  112  --- Training Error:  0.33556064018715626  --- Val. Error:  0.344512953514813\n",
      "Epoch  113  --- Training Error:  0.33470049935264873  --- Val. Error:  0.3393454880418371\n",
      "Epoch  114  --- Training Error:  0.3345900720179182  --- Val. Error:  0.3435017333391561\n",
      "Epoch  115  --- Training Error:  0.3337671168967516  --- Val. Error:  0.33835117385635827\n",
      "Epoch  116  --- Training Error:  0.3337045310664558  --- Val. Error:  0.3425840893300446\n",
      "Epoch  117  --- Training Error:  0.3329192548151489  --- Val. Error:  0.3374428380931746\n",
      "Epoch  118  --- Training Error:  0.3329178108952821  --- Val. Error:  0.3417731889757702\n",
      "Epoch  119  --- Training Error:  0.3321740676240372  --- Val. Error:  0.3366387749410096\n",
      "Epoch  120  --- Training Error:  0.3322138849349372  --- Val. Error:  0.3410540141656735\n",
      "Epoch  121  --- Training Error:  0.3314759307476274  --- Val. Error:  0.3358839353013865\n",
      "Epoch  122  --- Training Error:  0.33151337012153465  --- Val. Error:  0.34033730379617416\n",
      "Epoch  123  --- Training Error:  0.33079851793249115  --- Val. Error:  0.3351484949904981\n",
      "Epoch  124  --- Training Error:  0.3308365786008478  --- Val. Error:  0.3396451942453042\n",
      "Epoch  125  --- Training Error:  0.33010329586519854  --- Val. Error:  0.33439717582881257\n",
      "Epoch  126  --- Training Error:  0.33008993655777874  --- Val. Error:  0.3388707252992918\n",
      "Epoch  127  --- Training Error:  0.32934593958065195  --- Val. Error:  0.3335807714945527\n",
      "Epoch  128  --- Training Error:  0.329367680264291  --- Val. Error:  0.3381198344259577\n",
      "Epoch  129  --- Training Error:  0.32861573860865784  --- Val. Error:  0.33279229208997735\n",
      "Epoch  130  --- Training Error:  0.32857332541239836  --- Val. Error:  0.33728845125381246\n",
      "Epoch  131  --- Training Error:  0.3277798242416481  --- Val. Error:  0.3318970624391889\n",
      "Epoch  132  --- Training Error:  0.32765611103810227  --- Val. Error:  0.33632608861525093\n",
      "Epoch  133  --- Training Error:  0.3268476515020036  --- Val. Error:  0.3309052001830971\n",
      "Epoch  134  --- Training Error:  0.32671707975827297  --- Val. Error:  0.33533820700411154\n",
      "Epoch  135  --- Training Error:  0.3259092813322243  --- Val. Error:  0.32990898155610227\n",
      "Epoch  136  --- Training Error:  0.32576269816301223  --- Val. Error:  0.33433567899161915\n",
      "Epoch  137  --- Training Error:  0.32500461126804886  --- Val. Error:  0.32894264755492897\n",
      "Epoch  138  --- Training Error:  0.32489102608759013  --- Val. Error:  0.3334232099042861\n",
      "Epoch  139  --- Training Error:  0.32417968894406124  --- Val. Error:  0.3280556709711841\n",
      "Epoch  140  --- Training Error:  0.3240734444660479  --- Val. Error:  0.3325718372556054\n",
      "Epoch  141  --- Training Error:  0.3234002267690886  --- Val. Error:  0.32721580417124485\n",
      "Epoch  142  --- Training Error:  0.32332942953966454  --- Val. Error:  0.33179447908126436\n",
      "Epoch  143  --- Training Error:  0.32270732018285125  --- Val. Error:  0.3264618469918339\n",
      "Epoch  144  --- Training Error:  0.3226521351608617  --- Val. Error:  0.3310880628301111\n",
      "Epoch  145  --- Training Error:  0.3220269404077513  --- Val. Error:  0.32572032584286104\n",
      "Epoch  146  --- Training Error:  0.3219579125682374  --- Val. Error:  0.3303640289385312\n",
      "Epoch  147  --- Training Error:  0.32135179913958106  --- Val. Error:  0.3249809606945323\n",
      "Epoch  148  --- Training Error:  0.32125658553916103  --- Val. Error:  0.3296306609191015\n",
      "Epoch  149  --- Training Error:  0.32063187705842355  --- Val. Error:  0.32420036984503964\n",
      "Epoch  150  --- Training Error:  0.32053060675046086  --- Val. Error:  0.32887079722206186\n",
      "Epoch  151  --- Training Error:  0.319925775634359  --- Val. Error:  0.32343369751738565\n",
      "Epoch  152  --- Training Error:  0.31982992240661506  --- Val. Error:  0.32813374556383323\n",
      "Epoch  153  --- Training Error:  0.31924378770444745  --- Val. Error:  0.3226905601467139\n",
      "Epoch  154  --- Training Error:  0.31914463873462334  --- Val. Error:  0.327413734410409\n",
      "Epoch  155  --- Training Error:  0.3185402313093138  --- Val. Error:  0.3219284830965253\n",
      "Epoch  156  --- Training Error:  0.3184436144657766  --- Val. Error:  0.32667651901910655\n",
      "Epoch  157  --- Training Error:  0.3178417952293609  --- Val. Error:  0.3211694307869085\n",
      "Epoch  158  --- Training Error:  0.317754613352529  --- Val. Error:  0.32594948912770816\n",
      "Epoch  159  --- Training Error:  0.3171555781390735  --- Val. Error:  0.32042310612889124\n",
      "Epoch  160  --- Training Error:  0.3170646977470908  --- Val. Error:  0.3252199981198478\n",
      "Epoch  161  --- Training Error:  0.31646021299229105  --- Val. Error:  0.3196693640642379\n",
      "Epoch  162  --- Training Error:  0.3163318601587322  --- Val. Error:  0.32444100432517425\n",
      "Epoch  163  --- Training Error:  0.3157147628381897  --- Val. Error:  0.3188709090260295\n",
      "Epoch  164  --- Training Error:  0.3156020100119599  --- Val. Error:  0.32366455972091135\n",
      "Epoch  165  --- Training Error:  0.31495691549351224  --- Val. Error:  0.3180628963128862\n",
      "Epoch  166  --- Training Error:  0.3148437449587567  --- Val. Error:  0.32285899268776824\n",
      "Epoch  167  --- Training Error:  0.3142381676538756  --- Val. Error:  0.3172889031566071\n",
      "Epoch  168  --- Training Error:  0.31413844359429405  --- Val. Error:  0.32211176657768853\n",
      "Epoch  169  --- Training Error:  0.3135602918290934  --- Val. Error:  0.31655700377065915\n",
      "Epoch  170  --- Training Error:  0.31348568587901987  --- Val. Error:  0.3214217929485299\n",
      "Epoch  171  --- Training Error:  0.3129398102549335  --- Val. Error:  0.3158814895774379\n",
      "Epoch  172  --- Training Error:  0.312881675358304  --- Val. Error:  0.32078454742185675\n",
      "Epoch  173  --- Training Error:  0.31237591544091803  --- Val. Error:  0.3152617846566791\n",
      "Epoch  174  --- Training Error:  0.3123394988212285  --- Val. Error:  0.3202133797983275\n",
      "Epoch  175  --- Training Error:  0.31185844509323235  --- Val. Error:  0.31469152710584114\n",
      "Epoch  176  --- Training Error:  0.31182059262831774  --- Val. Error:  0.31966653963176817\n",
      "Epoch  177  --- Training Error:  0.3113531673761941  --- Val. Error:  0.31413327775110345\n",
      "Epoch  178  --- Training Error:  0.31133206122118035  --- Val. Error:  0.31915169205093946\n",
      "Epoch  179  --- Training Error:  0.31086940253394085  --- Val. Error:  0.31359879564080007\n",
      "Epoch  180  --- Training Error:  0.3107978096115718  --- Val. Error:  0.31858482154882783\n",
      "Epoch  181  --- Training Error:  0.31034332918914964  --- Val. Error:  0.3130199781334518\n",
      "Epoch  182  --- Training Error:  0.31026553029579856  --- Val. Error:  0.31802088467997996\n",
      "Epoch  183  --- Training Error:  0.30981133572883607  --- Val. Error:  0.31243993961376737\n",
      "Epoch  184  --- Training Error:  0.3097062754356767  --- Val. Error:  0.31742663886647754\n",
      "Epoch  185  --- Training Error:  0.30925572150960995  --- Val. Error:  0.31183411957056956\n",
      "Epoch  186  --- Training Error:  0.3091556897536079  --- Val. Error:  0.3168410781170943\n",
      "Epoch  187  --- Training Error:  0.30871493090251484  --- Val. Error:  0.3112443740583359\n",
      "Epoch  188  --- Training Error:  0.30860379802723453  --- Val. Error:  0.3162549568311906\n",
      "Epoch  189  --- Training Error:  0.30819707968045584  --- Val. Error:  0.3106749290266741\n",
      "Epoch  190  --- Training Error:  0.30809780855155705  --- Val. Error:  0.31571860532059315\n",
      "Epoch  191  --- Training Error:  0.30769679392180654  --- Val. Error:  0.3101241239940268\n",
      "Epoch  192  --- Training Error:  0.30756953196999887  --- Val. Error:  0.3151591583881169\n",
      "Epoch  193  --- Training Error:  0.3071745853572881  --- Val. Error:  0.3095517172960394\n",
      "Epoch  194  --- Training Error:  0.3070341456933894  --- Val. Error:  0.3145917547363595\n",
      "Epoch  195  --- Training Error:  0.3066190091846162  --- Val. Error:  0.3089466653517414\n",
      "Epoch  196  --- Training Error:  0.30644476450141794  --- Val. Error:  0.31396267906098047\n",
      "Epoch  197  --- Training Error:  0.30601745600738867  --- Val. Error:  0.30829735202096553\n",
      "Epoch  198  --- Training Error:  0.3058345414969697  --- Val. Error:  0.3133099010885239\n",
      "Epoch  199  --- Training Error:  0.3054100885517549  --- Val. Error:  0.3076437711655119\n"
     ]
    }
   ],
   "source": [
    "parameters, training_loss, validation_loss, error = train_model(x_train_flattened_standardized, y_train, x_test_flattened_standardized, y_test, rna, lrate = 0.01, num_iterations = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the training, the error reduction across the different stages is displayed:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss, label = \"Training error\")\n",
    "plt.plot(validation_loss, label = \"Validation error\")\n",
    "plt.xlabel(\"Num. of epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error during training\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='9'></a>\n",
    "# **9.- Prediction**\n",
    "Once the neural network is designed and trained, the main objective is to make predictions with unseen images. To achieve this, we design the method to evaluate the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, parameters, labels):\n",
    "    # Obtain predictions with the current weights\n",
    "    predictions, cache = forward_activation(dataset, parameters)\n",
    "\n",
    "    # Calculate the loss with these predictions\n",
    "    error = cost_function(predictions, labels)\n",
    "\n",
    "    return predictions, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate the ANN with unknown data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with unknown data:  0.31264615864689455\n"
     ]
    }
   ],
   "source": [
    "predicciones, error_test = predict(x_test_flattened_standardized, parameters, y_test.T)\n",
    "print(\"Error with unknown data: \", error_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
